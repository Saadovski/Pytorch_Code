{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from List_to_Pytorch_Dataset import dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import CNN1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2797\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 0  : \"STD\",\n",
    "           1  : \"WAL\",\n",
    "           2  : \"JOG\",\n",
    "           3  : \"JUM\",\n",
    "           4  : \"STU\",\n",
    "           5  : \"STN\",\n",
    "           6  : \"SCH\",\n",
    "           7  : \"SIT\",\n",
    "           8  : \"CHU\",\n",
    "           9  : \"CSI\",\n",
    "           10 : \"CSO\",\n",
    "           11 : \"FOL\",\n",
    "           12 : \"FKL\",\n",
    "           13 : \"BSC\",\n",
    "           14 : \"SDL\"}\n",
    "\n",
    "classification_map = {}\n",
    "\n",
    "for key, value in labels.items():\n",
    "    classification_map[value] = {\"TP\" : 0,\n",
    "                                 \"FP\" : 0,\n",
    "                                 \"TN\" : 0,\n",
    "                                 \"FN\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "\n",
    "            for key, value in labels.items():\n",
    "                for i in range(len(y)):\n",
    "                    if y[i] == key:\n",
    "                        if pred[i].argmax() == key:\n",
    "                            classification_map[value][\"TP\"] += 1\n",
    "                        else:\n",
    "                            classification_map[value][\"FN\"] += 1\n",
    "                    elif pred[i].argmax() == key:\n",
    "                        classification_map[value][\"FP\"] += 1\n",
    "                    else:\n",
    "                        classification_map[value][\"TN\"] += 1\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            #model loss and accuracy\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    #model stats\n",
    "    valid_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = CNN1D.CNN().to(device)\n",
    "    model.train()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 75\n",
    "\n",
    "    # Initialize the loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #creating datasets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    #Dataloaders for the datasets\n",
    "    train_dataloader = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "    test_dataloader = DataLoader(test_set, batch_size = 64, shuffle = True)\n",
    "    \n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    valid_loop(test_dataloader, model, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.712485  [    0/ 2237]\n",
      "loss: 2.186092  [  640/ 2237]\n",
      "loss: 1.492962  [ 1280/ 2237]\n",
      "loss: 1.306369  [ 1920/ 2237]\n",
      "loss: 0.860147  [    0/ 2237]\n",
      "loss: 1.197293  [  640/ 2237]\n",
      "loss: 0.936832  [ 1280/ 2237]\n",
      "loss: 0.638771  [ 1920/ 2237]\n",
      "loss: 0.586583  [    0/ 2237]\n",
      "loss: 0.495418  [  640/ 2237]\n",
      "loss: 0.634991  [ 1280/ 2237]\n",
      "loss: 0.637978  [ 1920/ 2237]\n",
      "loss: 0.444129  [    0/ 2237]\n",
      "loss: 0.476215  [  640/ 2237]\n",
      "loss: 0.592631  [ 1280/ 2237]\n",
      "loss: 0.428980  [ 1920/ 2237]\n",
      "loss: 0.241496  [    0/ 2237]\n",
      "loss: 0.262552  [  640/ 2237]\n",
      "loss: 0.495441  [ 1280/ 2237]\n",
      "loss: 0.445294  [ 1920/ 2237]\n",
      "loss: 0.446908  [    0/ 2237]\n",
      "loss: 0.336536  [  640/ 2237]\n",
      "loss: 0.451514  [ 1280/ 2237]\n",
      "loss: 0.296336  [ 1920/ 2237]\n",
      "loss: 0.181393  [    0/ 2237]\n",
      "loss: 0.186138  [  640/ 2237]\n",
      "loss: 0.383402  [ 1280/ 2237]\n",
      "loss: 0.198481  [ 1920/ 2237]\n",
      "loss: 0.150080  [    0/ 2237]\n",
      "loss: 0.241262  [  640/ 2237]\n",
      "loss: 0.081042  [ 1280/ 2237]\n",
      "loss: 0.233934  [ 1920/ 2237]\n",
      "loss: 0.103547  [    0/ 2237]\n",
      "loss: 0.076202  [  640/ 2237]\n",
      "loss: 0.105295  [ 1280/ 2237]\n",
      "loss: 0.142550  [ 1920/ 2237]\n",
      "loss: 0.043888  [    0/ 2237]\n",
      "loss: 0.196286  [  640/ 2237]\n",
      "loss: 0.155761  [ 1280/ 2237]\n",
      "loss: 0.044751  [ 1920/ 2237]\n",
      "loss: 0.062095  [    0/ 2237]\n",
      "loss: 0.273446  [  640/ 2237]\n",
      "loss: 0.419490  [ 1280/ 2237]\n",
      "loss: 0.148378  [ 1920/ 2237]\n",
      "loss: 0.090774  [    0/ 2237]\n",
      "loss: 0.185313  [  640/ 2237]\n",
      "loss: 0.061961  [ 1280/ 2237]\n",
      "loss: 0.005408  [ 1920/ 2237]\n",
      "loss: 0.010974  [    0/ 2237]\n",
      "loss: 0.024384  [  640/ 2237]\n",
      "loss: 0.036590  [ 1280/ 2237]\n",
      "loss: 0.063225  [ 1920/ 2237]\n",
      "loss: 0.063217  [    0/ 2237]\n",
      "loss: 0.159734  [  640/ 2237]\n",
      "loss: 0.158028  [ 1280/ 2237]\n",
      "loss: 0.123571  [ 1920/ 2237]\n",
      "loss: 0.035191  [    0/ 2237]\n",
      "loss: 0.154287  [  640/ 2237]\n",
      "loss: 0.015536  [ 1280/ 2237]\n",
      "loss: 0.055694  [ 1920/ 2237]\n",
      "loss: 0.054192  [    0/ 2237]\n",
      "loss: 0.051261  [  640/ 2237]\n",
      "loss: 0.063966  [ 1280/ 2237]\n",
      "loss: 0.093011  [ 1920/ 2237]\n",
      "loss: 0.021619  [    0/ 2237]\n",
      "loss: 0.031374  [  640/ 2237]\n",
      "loss: 0.040582  [ 1280/ 2237]\n",
      "loss: 0.047528  [ 1920/ 2237]\n",
      "loss: 0.067155  [    0/ 2237]\n",
      "loss: 0.070286  [  640/ 2237]\n",
      "loss: 0.113943  [ 1280/ 2237]\n",
      "loss: 0.070095  [ 1920/ 2237]\n",
      "loss: 0.014952  [    0/ 2237]\n",
      "loss: 0.008984  [  640/ 2237]\n",
      "loss: 0.054504  [ 1280/ 2237]\n",
      "loss: 0.063084  [ 1920/ 2237]\n",
      "loss: 0.001298  [    0/ 2237]\n",
      "loss: 0.005902  [  640/ 2237]\n",
      "loss: 0.062452  [ 1280/ 2237]\n",
      "loss: 0.006518  [ 1920/ 2237]\n",
      "loss: 0.005857  [    0/ 2237]\n",
      "loss: 0.004102  [  640/ 2237]\n",
      "loss: 0.002228  [ 1280/ 2237]\n",
      "loss: 0.003556  [ 1920/ 2237]\n",
      "loss: 0.001876  [    0/ 2237]\n",
      "loss: 0.001389  [  640/ 2237]\n",
      "loss: 0.084326  [ 1280/ 2237]\n",
      "loss: 0.051902  [ 1920/ 2237]\n",
      "loss: 0.013467  [    0/ 2237]\n",
      "loss: 0.002631  [  640/ 2237]\n",
      "loss: 0.013253  [ 1280/ 2237]\n",
      "loss: 0.017171  [ 1920/ 2237]\n",
      "loss: 0.033881  [    0/ 2237]\n",
      "loss: 0.003690  [  640/ 2237]\n",
      "loss: 0.007333  [ 1280/ 2237]\n",
      "loss: 0.008050  [ 1920/ 2237]\n",
      "loss: 0.001699  [    0/ 2237]\n",
      "loss: 0.001413  [  640/ 2237]\n",
      "loss: 0.027966  [ 1280/ 2237]\n",
      "loss: 0.008910  [ 1920/ 2237]\n",
      "loss: 0.001388  [    0/ 2237]\n",
      "loss: 0.113338  [  640/ 2237]\n",
      "loss: 0.002314  [ 1280/ 2237]\n",
      "loss: 0.067542  [ 1920/ 2237]\n",
      "loss: 0.023254  [    0/ 2237]\n",
      "loss: 0.003993  [  640/ 2237]\n",
      "loss: 0.001747  [ 1280/ 2237]\n",
      "loss: 0.010590  [ 1920/ 2237]\n",
      "loss: 0.000918  [    0/ 2237]\n",
      "loss: 0.020490  [  640/ 2237]\n",
      "loss: 0.016069  [ 1280/ 2237]\n",
      "loss: 0.075094  [ 1920/ 2237]\n",
      "loss: 0.013011  [    0/ 2237]\n",
      "loss: 0.008413  [  640/ 2237]\n",
      "loss: 0.106356  [ 1280/ 2237]\n",
      "loss: 0.071209  [ 1920/ 2237]\n",
      "loss: 0.018949  [    0/ 2237]\n",
      "loss: 0.029535  [  640/ 2237]\n",
      "loss: 0.004906  [ 1280/ 2237]\n",
      "loss: 0.022261  [ 1920/ 2237]\n",
      "loss: 0.069346  [    0/ 2237]\n",
      "loss: 0.086551  [  640/ 2237]\n",
      "loss: 0.034239  [ 1280/ 2237]\n",
      "loss: 0.051429  [ 1920/ 2237]\n",
      "loss: 0.123491  [    0/ 2237]\n",
      "loss: 0.001574  [  640/ 2237]\n",
      "loss: 0.013653  [ 1280/ 2237]\n",
      "loss: 0.023651  [ 1920/ 2237]\n",
      "loss: 0.010145  [    0/ 2237]\n",
      "loss: 0.022971  [  640/ 2237]\n",
      "loss: 0.016851  [ 1280/ 2237]\n",
      "loss: 0.002465  [ 1920/ 2237]\n",
      "loss: 0.013648  [    0/ 2237]\n",
      "loss: 0.003890  [  640/ 2237]\n",
      "loss: 0.008237  [ 1280/ 2237]\n",
      "loss: 0.011667  [ 1920/ 2237]\n",
      "loss: 0.003491  [    0/ 2237]\n",
      "loss: 0.019936  [  640/ 2237]\n",
      "loss: 0.000086  [ 1280/ 2237]\n",
      "loss: 0.000826  [ 1920/ 2237]\n",
      "loss: 0.018639  [    0/ 2237]\n",
      "loss: 0.000408  [  640/ 2237]\n",
      "loss: 0.002671  [ 1280/ 2237]\n",
      "loss: 0.003834  [ 1920/ 2237]\n",
      "loss: 0.034629  [    0/ 2237]\n",
      "loss: 0.002257  [  640/ 2237]\n",
      "loss: 0.014192  [ 1280/ 2237]\n",
      "loss: 0.008777  [ 1920/ 2237]\n",
      "loss: 0.030653  [    0/ 2237]\n",
      "loss: 0.003031  [  640/ 2237]\n",
      "loss: 0.001657  [ 1280/ 2237]\n",
      "loss: 0.001474  [ 1920/ 2237]\n",
      "loss: 0.013395  [    0/ 2237]\n",
      "loss: 0.001768  [  640/ 2237]\n",
      "loss: 0.030067  [ 1280/ 2237]\n",
      "loss: 0.004239  [ 1920/ 2237]\n",
      "loss: 0.039009  [    0/ 2237]\n",
      "loss: 0.006233  [  640/ 2237]\n",
      "loss: 0.014293  [ 1280/ 2237]\n",
      "loss: 0.014819  [ 1920/ 2237]\n",
      "loss: 0.014156  [    0/ 2237]\n",
      "loss: 0.023764  [  640/ 2237]\n",
      "loss: 0.049603  [ 1280/ 2237]\n",
      "loss: 0.013410  [ 1920/ 2237]\n",
      "loss: 0.002411  [    0/ 2237]\n",
      "loss: 0.000786  [  640/ 2237]\n",
      "loss: 0.048766  [ 1280/ 2237]\n",
      "loss: 0.002170  [ 1920/ 2237]\n",
      "loss: 0.001284  [    0/ 2237]\n",
      "loss: 0.039521  [  640/ 2237]\n",
      "loss: 0.078213  [ 1280/ 2237]\n",
      "loss: 0.008452  [ 1920/ 2237]\n",
      "loss: 0.001251  [    0/ 2237]\n",
      "loss: 0.005667  [  640/ 2237]\n",
      "loss: 0.000135  [ 1280/ 2237]\n",
      "loss: 0.000112  [ 1920/ 2237]\n",
      "loss: 0.000506  [    0/ 2237]\n",
      "loss: 0.105404  [  640/ 2237]\n",
      "loss: 0.001917  [ 1280/ 2237]\n",
      "loss: 0.016629  [ 1920/ 2237]\n",
      "loss: 0.000482  [    0/ 2237]\n",
      "loss: 0.004157  [  640/ 2237]\n",
      "loss: 0.064284  [ 1280/ 2237]\n",
      "loss: 0.039981  [ 1920/ 2237]\n",
      "loss: 0.004784  [    0/ 2237]\n",
      "loss: 0.004846  [  640/ 2237]\n",
      "loss: 0.052176  [ 1280/ 2237]\n",
      "loss: 0.102284  [ 1920/ 2237]\n",
      "loss: 0.098710  [    0/ 2237]\n",
      "loss: 0.067266  [  640/ 2237]\n",
      "loss: 0.154096  [ 1280/ 2237]\n",
      "loss: 0.038404  [ 1920/ 2237]\n",
      "loss: 0.057589  [    0/ 2237]\n",
      "loss: 0.057619  [  640/ 2237]\n",
      "loss: 0.029806  [ 1280/ 2237]\n",
      "loss: 0.004322  [ 1920/ 2237]\n",
      "loss: 0.004718  [    0/ 2237]\n",
      "loss: 0.014663  [  640/ 2237]\n",
      "loss: 0.014016  [ 1280/ 2237]\n",
      "loss: 0.001254  [ 1920/ 2237]\n",
      "loss: 0.001882  [    0/ 2237]\n",
      "loss: 0.017434  [  640/ 2237]\n",
      "loss: 0.025543  [ 1280/ 2237]\n",
      "loss: 0.008019  [ 1920/ 2237]\n",
      "loss: 0.071322  [    0/ 2237]\n",
      "loss: 0.006382  [  640/ 2237]\n",
      "loss: 0.002809  [ 1280/ 2237]\n",
      "loss: 0.006682  [ 1920/ 2237]\n",
      "loss: 0.000709  [    0/ 2237]\n",
      "loss: 0.001413  [  640/ 2237]\n",
      "loss: 0.000318  [ 1280/ 2237]\n",
      "loss: 0.000664  [ 1920/ 2237]\n",
      "loss: 0.000550  [    0/ 2237]\n",
      "loss: 0.000124  [  640/ 2237]\n",
      "loss: 0.000123  [ 1280/ 2237]\n",
      "loss: 0.000125  [ 1920/ 2237]\n",
      "loss: 0.000295  [    0/ 2237]\n",
      "loss: 0.000449  [  640/ 2237]\n",
      "loss: 0.000033  [ 1280/ 2237]\n",
      "loss: 0.000070  [ 1920/ 2237]\n",
      "loss: 0.000088  [    0/ 2237]\n",
      "loss: 0.001357  [  640/ 2237]\n",
      "loss: 0.000013  [ 1280/ 2237]\n",
      "loss: 0.000045  [ 1920/ 2237]\n",
      "loss: 0.000015  [    0/ 2237]\n",
      "loss: 0.000031  [  640/ 2237]\n",
      "loss: 0.000007  [ 1280/ 2237]\n",
      "loss: 0.000041  [ 1920/ 2237]\n",
      "loss: 0.000047  [    0/ 2237]\n",
      "loss: 0.000065  [  640/ 2237]\n",
      "loss: 0.000066  [ 1280/ 2237]\n",
      "loss: 0.000273  [ 1920/ 2237]\n",
      "loss: 0.000037  [    0/ 2237]\n",
      "loss: 0.000031  [  640/ 2237]\n",
      "loss: 0.000025  [ 1280/ 2237]\n",
      "loss: 0.000075  [ 1920/ 2237]\n",
      "loss: 0.000019  [    0/ 2237]\n",
      "loss: 0.000052  [  640/ 2237]\n",
      "loss: 0.015119  [ 1280/ 2237]\n",
      "loss: 0.000015  [ 1920/ 2237]\n",
      "loss: 0.000057  [    0/ 2237]\n",
      "loss: 0.000508  [  640/ 2237]\n",
      "loss: 0.000340  [ 1280/ 2237]\n",
      "loss: 0.000051  [ 1920/ 2237]\n",
      "loss: 0.000380  [    0/ 2237]\n",
      "loss: 0.000068  [  640/ 2237]\n",
      "loss: 0.000010  [ 1280/ 2237]\n",
      "loss: 0.000020  [ 1920/ 2237]\n",
      "loss: 0.000106  [    0/ 2237]\n",
      "loss: 0.000195  [  640/ 2237]\n",
      "loss: 0.000003  [ 1280/ 2237]\n",
      "loss: 0.002974  [ 1920/ 2237]\n",
      "loss: 0.000010  [    0/ 2237]\n",
      "loss: 0.000024  [  640/ 2237]\n",
      "loss: 0.000038  [ 1280/ 2237]\n",
      "loss: 0.000018  [ 1920/ 2237]\n",
      "loss: 0.000019  [    0/ 2237]\n",
      "loss: 0.000256  [  640/ 2237]\n",
      "loss: 0.000224  [ 1280/ 2237]\n",
      "loss: 0.000908  [ 1920/ 2237]\n",
      "loss: 0.000152  [    0/ 2237]\n",
      "loss: 0.000007  [  640/ 2237]\n",
      "loss: 0.000456  [ 1280/ 2237]\n",
      "loss: 0.000009  [ 1920/ 2237]\n",
      "loss: 0.000016  [    0/ 2237]\n",
      "loss: 0.000014  [  640/ 2237]\n",
      "loss: 0.001043  [ 1280/ 2237]\n",
      "loss: 0.000104  [ 1920/ 2237]\n",
      "loss: 0.013256  [    0/ 2237]\n",
      "loss: 0.021625  [  640/ 2237]\n",
      "loss: 0.063751  [ 1280/ 2237]\n",
      "loss: 0.052327  [ 1920/ 2237]\n",
      "loss: 0.007725  [    0/ 2237]\n",
      "loss: 0.049872  [  640/ 2237]\n",
      "loss: 0.002424  [ 1280/ 2237]\n",
      "loss: 0.282937  [ 1920/ 2237]\n",
      "loss: 0.052826  [    0/ 2237]\n",
      "loss: 0.071466  [  640/ 2237]\n",
      "loss: 0.060004  [ 1280/ 2237]\n",
      "loss: 0.009500  [ 1920/ 2237]\n",
      "loss: 0.149649  [    0/ 2237]\n",
      "loss: 0.069391  [  640/ 2237]\n",
      "loss: 0.030406  [ 1280/ 2237]\n",
      "loss: 0.076701  [ 1920/ 2237]\n",
      "loss: 0.004368  [    0/ 2237]\n",
      "loss: 0.049589  [  640/ 2237]\n",
      "loss: 0.161461  [ 1280/ 2237]\n",
      "loss: 0.008543  [ 1920/ 2237]\n",
      "loss: 0.049451  [    0/ 2237]\n",
      "loss: 0.030872  [  640/ 2237]\n",
      "loss: 0.009555  [ 1280/ 2237]\n",
      "loss: 0.035707  [ 1920/ 2237]\n",
      "loss: 0.003685  [    0/ 2237]\n",
      "loss: 0.024809  [  640/ 2237]\n",
      "loss: 0.012299  [ 1280/ 2237]\n",
      "loss: 0.105244  [ 1920/ 2237]\n",
      "loss: 0.166637  [    0/ 2237]\n",
      "loss: 0.004627  [  640/ 2237]\n",
      "loss: 0.001346  [ 1280/ 2237]\n",
      "loss: 0.060358  [ 1920/ 2237]\n",
      "Validation Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.357643 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'STD': {'Sensitivity': 0.9655172413793104, 'Specificity': 1.0, 'Recall': 0.9655172413793104, 'Precision': 1.0, 'Accuracy': 0.9982142857142857, 'F-score': 0.9824561403508772}, 'WAL': {'Sensitivity': 0.92, 'Specificity': 0.9921568627450981, 'Recall': 0.92, 'Precision': 0.92, 'Accuracy': 0.9857142857142858, 'F-score': 0.92}, 'JOG': {'Sensitivity': 0.96, 'Specificity': 0.9962616822429906, 'Recall': 0.96, 'Precision': 0.9230769230769231, 'Accuracy': 0.9946428571428572, 'F-score': 0.9411764705882353}, 'JUM': {'Sensitivity': 0.972972972972973, 'Specificity': 0.9904397705544933, 'Recall': 0.972972972972973, 'Precision': 0.8780487804878049, 'Accuracy': 0.9892857142857143, 'F-score': 0.9230769230769231}, 'STU': {'Sensitivity': 0.8571428571428571, 'Specificity': 0.9960861056751468, 'Recall': 0.8571428571428571, 'Precision': 0.9545454545454546, 'Accuracy': 0.9839285714285714, 'F-score': 0.9032258064516129}, 'STN': {'Sensitivity': 0.8717948717948718, 'Specificity': 0.9904030710172744, 'Recall': 0.8717948717948718, 'Precision': 0.8717948717948718, 'Accuracy': 0.9821428571428571, 'F-score': 0.8717948717948718}, 'SCH': {'Sensitivity': 1.0, 'Specificity': 0.9980806142034548, 'Recall': 1.0, 'Precision': 0.975, 'Accuracy': 0.9982142857142857, 'F-score': 0.9873417721518988}, 'SIT': {'Sensitivity': 1.0, 'Specificity': 1.0, 'Recall': 1.0, 'Precision': 1.0, 'Accuracy': 1.0, 'F-score': 1.0}, 'CHU': {'Sensitivity': 0.96, 'Specificity': 0.9981308411214953, 'Recall': 0.96, 'Precision': 0.96, 'Accuracy': 0.9964285714285714, 'F-score': 0.96}, 'CSI': {'Sensitivity': 1.0, 'Specificity': 0.9961464354527938, 'Recall': 1.0, 'Precision': 0.9534883720930233, 'Accuracy': 0.9964285714285714, 'F-score': 0.9761904761904762}, 'CSO': {'Sensitivity': 0.9782608695652174, 'Specificity': 0.9980544747081712, 'Recall': 0.9782608695652174, 'Precision': 0.9782608695652174, 'Accuracy': 0.9964285714285714, 'F-score': 0.9782608695652175}, 'FOL': {'Sensitivity': 0.972972972972973, 'Specificity': 0.982791586998088, 'Recall': 0.972972972972973, 'Precision': 0.8, 'Accuracy': 0.9821428571428571, 'F-score': 0.8780487804878049}, 'FKL': {'Sensitivity': 0.8611111111111112, 'Specificity': 0.9961832061068703, 'Recall': 0.8611111111111112, 'Precision': 0.9393939393939394, 'Accuracy': 0.9875, 'F-score': 0.8985507246376813}, 'BSC': {'Sensitivity': 0.7894736842105263, 'Specificity': 0.9961685823754789, 'Recall': 0.7894736842105263, 'Precision': 0.9375, 'Accuracy': 0.9821428571428571, 'F-score': 0.8571428571428572}, 'SDL': {'Sensitivity': 0.8421052631578947, 'Specificity': 0.9904214559386973, 'Recall': 0.8421052631578947, 'Precision': 0.8648648648648649, 'Accuracy': 0.9803571428571428, 'F-score': 0.8533333333333334}}\n"
     ]
    }
   ],
   "source": [
    "stats_map = {}\n",
    "for key, value in labels.items():\n",
    "    stats_map[value] = {\n",
    "        \"Sensitivity\" : float(classification_map[value][\"TP\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"FN\"]),\n",
    "        \"Specificity\" : float(classification_map[value][\"TN\"]) / float(classification_map[value][\"TN\"] + classification_map[value][\"FP\"]),\n",
    "        \"Recall\" : float(classification_map[value][\"TP\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"FN\"]),\n",
    "        \"Precision\" : float(classification_map[value][\"TP\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"FP\"]),\n",
    "        \"Accuracy\" : float(classification_map[value][\"TP\"] + classification_map[value][\"TN\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"TN\"] + classification_map[value][\"FP\"] + classification_map[value][\"FN\"])\n",
    "    }\n",
    "    stats_map[value][\"F-score\"] = 2.0 / float(1.0 / float(stats_map[value][\"Precision\"]) + 1.0 / float(stats_map[value][\"Recall\"]))\n",
    "print(stats_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e29914317381cb5b054684ec136cf5f9d23d3fafddd70669a3da3e14954aacc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from List_to_Pytorch_Dataset import dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import CNN1D\n",
    "import Smaller_input_CNN\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 2797\n",
      "Data sample size: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Data sample size: {len(dataset[0][0][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 0  : \"STD\",\n",
    "           1  : \"WAL\",\n",
    "           2  : \"JOG\",\n",
    "           3  : \"JUM\",\n",
    "           4  : \"STU\",\n",
    "           5  : \"STN\",\n",
    "           6  : \"SCH\",\n",
    "           7  : \"SIT\",\n",
    "           8  : \"CHU\",\n",
    "           9  : \"CSI\",\n",
    "           10 : \"CSO\",\n",
    "           11 : \"FOL\",\n",
    "           12 : \"FKL\",\n",
    "           13 : \"BSC\",\n",
    "           14 : \"SDL\"}\n",
    "\n",
    "classification_map = {}\n",
    "\n",
    "for key, value in labels.items():\n",
    "    classification_map[value] = {\"TP\" : 0,\n",
    "                                 \"FP\" : 0,\n",
    "                                 \"TN\" : 0,\n",
    "                                 \"FN\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    valid_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "\n",
    "            for key, value in labels.items():\n",
    "                for i in range(len(y)):\n",
    "                    if y[i] == key:\n",
    "                        if pred[i].argmax() == key:\n",
    "                            classification_map[value][\"TP\"] += 1\n",
    "                        else:\n",
    "                            classification_map[value][\"FN\"] += 1\n",
    "                    elif pred[i].argmax() == key:\n",
    "                        classification_map[value][\"FP\"] += 1\n",
    "                    else:\n",
    "                        classification_map[value][\"TN\"] += 1\n",
    "                \n",
    "\n",
    "            \n",
    "            \n",
    "            #model loss and accuracy\n",
    "            valid_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    #model stats\n",
    "    valid_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {valid_loss:>8f} \\n\\n\")\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = CNN1D.CNN().to(device)\n",
    "    model.train()\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    epochs = 50\n",
    "\n",
    "    # Initialize the loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    #creating datasets\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    #Dataloaders for the datasets\n",
    "    train_dataloader = DataLoader(train_set, batch_size = 64, shuffle = True)\n",
    "    test_dataloader = DataLoader(test_set, batch_size = 64, shuffle = True)\n",
    "    \n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    model_accuracy = valid_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "    return model_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.899162  [    0/ 2237]\n",
      "loss: 2.722261  [  640/ 2237]\n",
      "loss: 2.720768  [ 1280/ 2237]\n",
      "loss: 2.467215  [ 1920/ 2237]\n",
      "loss: 2.294560  [    0/ 2237]\n",
      "loss: 2.271122  [  640/ 2237]\n",
      "loss: 2.232650  [ 1280/ 2237]\n",
      "loss: 1.812074  [ 1920/ 2237]\n",
      "loss: 2.009011  [    0/ 2237]\n",
      "loss: 1.670400  [  640/ 2237]\n",
      "loss: 1.702777  [ 1280/ 2237]\n",
      "loss: 1.596867  [ 1920/ 2237]\n",
      "loss: 1.468806  [    0/ 2237]\n",
      "loss: 1.510196  [  640/ 2237]\n",
      "loss: 1.468573  [ 1280/ 2237]\n",
      "loss: 1.233488  [ 1920/ 2237]\n",
      "loss: 1.339675  [    0/ 2237]\n",
      "loss: 1.181476  [  640/ 2237]\n",
      "loss: 1.223030  [ 1280/ 2237]\n",
      "loss: 1.178825  [ 1920/ 2237]\n",
      "loss: 0.966490  [    0/ 2237]\n",
      "loss: 1.136310  [  640/ 2237]\n",
      "loss: 1.023296  [ 1280/ 2237]\n",
      "loss: 1.066477  [ 1920/ 2237]\n",
      "loss: 0.984348  [    0/ 2237]\n",
      "loss: 1.106387  [  640/ 2237]\n",
      "loss: 0.953201  [ 1280/ 2237]\n",
      "loss: 0.983134  [ 1920/ 2237]\n",
      "loss: 0.689992  [    0/ 2237]\n",
      "loss: 0.875749  [  640/ 2237]\n",
      "loss: 1.014603  [ 1280/ 2237]\n",
      "loss: 0.868099  [ 1920/ 2237]\n",
      "loss: 0.768228  [    0/ 2237]\n",
      "loss: 0.758537  [  640/ 2237]\n",
      "loss: 0.601805  [ 1280/ 2237]\n",
      "loss: 0.783558  [ 1920/ 2237]\n",
      "loss: 0.508174  [    0/ 2237]\n",
      "loss: 0.736690  [  640/ 2237]\n",
      "loss: 0.550304  [ 1280/ 2237]\n",
      "loss: 0.741036  [ 1920/ 2237]\n",
      "loss: 0.682295  [    0/ 2237]\n",
      "loss: 0.512406  [  640/ 2237]\n",
      "loss: 0.804727  [ 1280/ 2237]\n",
      "loss: 0.414430  [ 1920/ 2237]\n",
      "loss: 0.458764  [    0/ 2237]\n",
      "loss: 0.569440  [  640/ 2237]\n",
      "loss: 0.521717  [ 1280/ 2237]\n",
      "loss: 0.678974  [ 1920/ 2237]\n",
      "loss: 0.421598  [    0/ 2237]\n",
      "loss: 0.640210  [  640/ 2237]\n",
      "loss: 0.580487  [ 1280/ 2237]\n",
      "loss: 0.532267  [ 1920/ 2237]\n",
      "loss: 0.353333  [    0/ 2237]\n",
      "loss: 0.250741  [  640/ 2237]\n",
      "loss: 0.381864  [ 1280/ 2237]\n",
      "loss: 0.429080  [ 1920/ 2237]\n",
      "loss: 0.263198  [    0/ 2237]\n",
      "loss: 0.647429  [  640/ 2237]\n",
      "loss: 0.402550  [ 1280/ 2237]\n",
      "loss: 0.354325  [ 1920/ 2237]\n",
      "loss: 0.256121  [    0/ 2237]\n",
      "loss: 0.380670  [  640/ 2237]\n",
      "loss: 0.241008  [ 1280/ 2237]\n",
      "loss: 0.382299  [ 1920/ 2237]\n",
      "loss: 0.281088  [    0/ 2237]\n",
      "loss: 0.187054  [  640/ 2237]\n",
      "loss: 0.195758  [ 1280/ 2237]\n",
      "loss: 0.138696  [ 1920/ 2237]\n",
      "loss: 0.161618  [    0/ 2237]\n",
      "loss: 0.190502  [  640/ 2237]\n",
      "loss: 0.135984  [ 1280/ 2237]\n",
      "loss: 0.424918  [ 1920/ 2237]\n",
      "loss: 0.071819  [    0/ 2237]\n",
      "loss: 0.152195  [  640/ 2237]\n",
      "loss: 0.189137  [ 1280/ 2237]\n",
      "loss: 0.368739  [ 1920/ 2237]\n",
      "loss: 0.124915  [    0/ 2237]\n",
      "loss: 0.153363  [  640/ 2237]\n",
      "loss: 0.115534  [ 1280/ 2237]\n",
      "loss: 0.166160  [ 1920/ 2237]\n",
      "loss: 0.096121  [    0/ 2237]\n",
      "loss: 0.080005  [  640/ 2237]\n",
      "loss: 0.326568  [ 1280/ 2237]\n",
      "loss: 0.200076  [ 1920/ 2237]\n",
      "loss: 0.074079  [    0/ 2237]\n",
      "loss: 0.130902  [  640/ 2237]\n",
      "loss: 0.069452  [ 1280/ 2237]\n",
      "loss: 0.129789  [ 1920/ 2237]\n",
      "loss: 0.333943  [    0/ 2237]\n",
      "loss: 0.284780  [  640/ 2237]\n",
      "loss: 0.141781  [ 1280/ 2237]\n",
      "loss: 0.367609  [ 1920/ 2237]\n",
      "loss: 0.285906  [    0/ 2237]\n",
      "loss: 0.158035  [  640/ 2237]\n",
      "loss: 0.137948  [ 1280/ 2237]\n",
      "loss: 0.281683  [ 1920/ 2237]\n",
      "loss: 0.108745  [    0/ 2237]\n",
      "loss: 0.221875  [  640/ 2237]\n",
      "loss: 0.215335  [ 1280/ 2237]\n",
      "loss: 0.319322  [ 1920/ 2237]\n",
      "loss: 0.128316  [    0/ 2237]\n",
      "loss: 0.097092  [  640/ 2237]\n",
      "loss: 0.101381  [ 1280/ 2237]\n",
      "loss: 0.160441  [ 1920/ 2237]\n",
      "loss: 0.163986  [    0/ 2237]\n",
      "loss: 0.156958  [  640/ 2237]\n",
      "loss: 0.239284  [ 1280/ 2237]\n",
      "loss: 0.133222  [ 1920/ 2237]\n",
      "loss: 0.046312  [    0/ 2237]\n",
      "loss: 0.110382  [  640/ 2237]\n",
      "loss: 0.082059  [ 1280/ 2237]\n",
      "loss: 0.077829  [ 1920/ 2237]\n",
      "loss: 0.122237  [    0/ 2237]\n",
      "loss: 0.030952  [  640/ 2237]\n",
      "loss: 0.225318  [ 1280/ 2237]\n",
      "loss: 0.114190  [ 1920/ 2237]\n",
      "loss: 0.064888  [    0/ 2237]\n",
      "loss: 0.066076  [  640/ 2237]\n",
      "loss: 0.125776  [ 1280/ 2237]\n",
      "loss: 0.208396  [ 1920/ 2237]\n",
      "loss: 0.039065  [    0/ 2237]\n",
      "loss: 0.072433  [  640/ 2237]\n",
      "loss: 0.073859  [ 1280/ 2237]\n",
      "loss: 0.033553  [ 1920/ 2237]\n",
      "loss: 0.070592  [    0/ 2237]\n",
      "loss: 0.049593  [  640/ 2237]\n",
      "loss: 0.099798  [ 1280/ 2237]\n",
      "loss: 0.059421  [ 1920/ 2237]\n",
      "loss: 0.049512  [    0/ 2237]\n",
      "loss: 0.032665  [  640/ 2237]\n",
      "loss: 0.026077  [ 1280/ 2237]\n",
      "loss: 0.059944  [ 1920/ 2237]\n",
      "loss: 0.031193  [    0/ 2237]\n",
      "loss: 0.024819  [  640/ 2237]\n",
      "loss: 0.023470  [ 1280/ 2237]\n",
      "loss: 0.042750  [ 1920/ 2237]\n",
      "loss: 0.009677  [    0/ 2237]\n",
      "loss: 0.014249  [  640/ 2237]\n",
      "loss: 0.021678  [ 1280/ 2237]\n",
      "loss: 0.032316  [ 1920/ 2237]\n",
      "loss: 0.039665  [    0/ 2237]\n",
      "loss: 0.113508  [  640/ 2237]\n",
      "loss: 0.050104  [ 1280/ 2237]\n",
      "loss: 0.045797  [ 1920/ 2237]\n",
      "loss: 0.010285  [    0/ 2237]\n",
      "loss: 0.026303  [  640/ 2237]\n",
      "loss: 0.020491  [ 1280/ 2237]\n",
      "loss: 0.165071  [ 1920/ 2237]\n",
      "loss: 0.130556  [    0/ 2237]\n",
      "loss: 0.022441  [  640/ 2237]\n",
      "loss: 0.039279  [ 1280/ 2237]\n",
      "loss: 0.041206  [ 1920/ 2237]\n",
      "loss: 0.082355  [    0/ 2237]\n",
      "loss: 0.041173  [  640/ 2237]\n",
      "loss: 0.074064  [ 1280/ 2237]\n",
      "loss: 0.016496  [ 1920/ 2237]\n",
      "loss: 0.011485  [    0/ 2237]\n",
      "loss: 0.031836  [  640/ 2237]\n",
      "loss: 0.035803  [ 1280/ 2237]\n",
      "loss: 0.052760  [ 1920/ 2237]\n",
      "loss: 0.066541  [    0/ 2237]\n",
      "loss: 0.090555  [  640/ 2237]\n",
      "loss: 0.122030  [ 1280/ 2237]\n",
      "loss: 0.007920  [ 1920/ 2237]\n",
      "loss: 0.089590  [    0/ 2237]\n",
      "loss: 0.005316  [  640/ 2237]\n",
      "loss: 0.254107  [ 1280/ 2237]\n",
      "loss: 0.017741  [ 1920/ 2237]\n",
      "loss: 0.060462  [    0/ 2237]\n",
      "loss: 0.146702  [  640/ 2237]\n",
      "loss: 0.041909  [ 1280/ 2237]\n",
      "loss: 0.104255  [ 1920/ 2237]\n",
      "loss: 0.064669  [    0/ 2237]\n",
      "loss: 0.013510  [  640/ 2237]\n",
      "loss: 0.024731  [ 1280/ 2237]\n",
      "loss: 0.018411  [ 1920/ 2237]\n",
      "loss: 0.029900  [    0/ 2237]\n",
      "loss: 0.012172  [  640/ 2237]\n",
      "loss: 0.032608  [ 1280/ 2237]\n",
      "loss: 0.005217  [ 1920/ 2237]\n",
      "loss: 0.013174  [    0/ 2237]\n",
      "loss: 0.003807  [  640/ 2237]\n",
      "loss: 0.014000  [ 1280/ 2237]\n",
      "loss: 0.003221  [ 1920/ 2237]\n",
      "loss: 0.042620  [    0/ 2237]\n",
      "loss: 0.002404  [  640/ 2237]\n",
      "loss: 0.022134  [ 1280/ 2237]\n",
      "loss: 0.108834  [ 1920/ 2237]\n",
      "loss: 0.004773  [    0/ 2237]\n",
      "loss: 0.004422  [  640/ 2237]\n",
      "loss: 0.121786  [ 1280/ 2237]\n",
      "loss: 0.021643  [ 1920/ 2237]\n",
      "loss: 0.004619  [    0/ 2237]\n",
      "loss: 0.050092  [  640/ 2237]\n",
      "loss: 0.012642  [ 1280/ 2237]\n",
      "loss: 0.056239  [ 1920/ 2237]\n",
      "loss: 0.187599  [    0/ 2237]\n",
      "loss: 0.113360  [  640/ 2237]\n",
      "loss: 0.092465  [ 1280/ 2237]\n",
      "loss: 0.028126  [ 1920/ 2237]\n",
      "Validation Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.786681 \n",
      "\n",
      "\n",
      "loss: 3.116185  [    0/ 2237]\n",
      "loss: 2.676051  [  640/ 2237]\n",
      "loss: 2.614442  [ 1280/ 2237]\n",
      "loss: 2.413192  [ 1920/ 2237]\n",
      "loss: 2.282495  [    0/ 2237]\n",
      "loss: 1.816344  [  640/ 2237]\n",
      "loss: 2.122501  [ 1280/ 2237]\n",
      "loss: 2.063856  [ 1920/ 2237]\n",
      "loss: 1.856316  [    0/ 2237]\n",
      "loss: 1.528604  [  640/ 2237]\n",
      "loss: 1.607410  [ 1280/ 2237]\n",
      "loss: 1.601925  [ 1920/ 2237]\n",
      "loss: 1.379969  [    0/ 2237]\n",
      "loss: 1.449029  [  640/ 2237]\n",
      "loss: 1.598539  [ 1280/ 2237]\n",
      "loss: 1.250780  [ 1920/ 2237]\n",
      "loss: 1.063419  [    0/ 2237]\n",
      "loss: 1.123005  [  640/ 2237]\n",
      "loss: 1.110854  [ 1280/ 2237]\n",
      "loss: 1.351809  [ 1920/ 2237]\n",
      "loss: 1.343001  [    0/ 2237]\n",
      "loss: 0.783455  [  640/ 2237]\n",
      "loss: 0.927198  [ 1280/ 2237]\n",
      "loss: 1.026091  [ 1920/ 2237]\n",
      "loss: 0.772621  [    0/ 2237]\n",
      "loss: 0.877478  [  640/ 2237]\n",
      "loss: 0.816561  [ 1280/ 2237]\n",
      "loss: 0.945186  [ 1920/ 2237]\n",
      "loss: 0.812962  [    0/ 2237]\n",
      "loss: 0.863718  [  640/ 2237]\n",
      "loss: 0.621512  [ 1280/ 2237]\n",
      "loss: 0.703078  [ 1920/ 2237]\n",
      "loss: 0.681061  [    0/ 2237]\n",
      "loss: 0.537513  [  640/ 2237]\n",
      "loss: 0.708027  [ 1280/ 2237]\n",
      "loss: 0.653666  [ 1920/ 2237]\n",
      "loss: 0.514143  [    0/ 2237]\n",
      "loss: 0.462453  [  640/ 2237]\n",
      "loss: 0.827753  [ 1280/ 2237]\n",
      "loss: 0.685048  [ 1920/ 2237]\n",
      "loss: 0.612612  [    0/ 2237]\n",
      "loss: 0.743363  [  640/ 2237]\n",
      "loss: 0.432593  [ 1280/ 2237]\n",
      "loss: 0.379753  [ 1920/ 2237]\n",
      "loss: 0.371594  [    0/ 2237]\n",
      "loss: 0.461468  [  640/ 2237]\n",
      "loss: 0.347923  [ 1280/ 2237]\n",
      "loss: 0.479763  [ 1920/ 2237]\n",
      "loss: 0.302467  [    0/ 2237]\n",
      "loss: 0.342835  [  640/ 2237]\n",
      "loss: 0.125734  [ 1280/ 2237]\n",
      "loss: 0.347123  [ 1920/ 2237]\n",
      "loss: 0.204880  [    0/ 2237]\n",
      "loss: 0.336127  [  640/ 2237]\n",
      "loss: 0.252901  [ 1280/ 2237]\n",
      "loss: 0.308605  [ 1920/ 2237]\n",
      "loss: 0.489051  [    0/ 2237]\n",
      "loss: 0.399918  [  640/ 2237]\n",
      "loss: 0.290589  [ 1280/ 2237]\n",
      "loss: 0.140923  [ 1920/ 2237]\n",
      "loss: 0.281994  [    0/ 2237]\n",
      "loss: 0.314185  [  640/ 2237]\n",
      "loss: 0.168159  [ 1280/ 2237]\n",
      "loss: 0.411920  [ 1920/ 2237]\n",
      "loss: 0.369613  [    0/ 2237]\n",
      "loss: 0.294879  [  640/ 2237]\n",
      "loss: 0.366342  [ 1280/ 2237]\n",
      "loss: 0.201070  [ 1920/ 2237]\n",
      "loss: 0.308238  [    0/ 2237]\n",
      "loss: 0.087066  [  640/ 2237]\n",
      "loss: 0.234498  [ 1280/ 2237]\n",
      "loss: 0.163428  [ 1920/ 2237]\n",
      "loss: 0.187453  [    0/ 2237]\n",
      "loss: 0.201626  [  640/ 2237]\n",
      "loss: 0.259377  [ 1280/ 2237]\n",
      "loss: 0.134134  [ 1920/ 2237]\n",
      "loss: 0.156077  [    0/ 2237]\n",
      "loss: 0.212836  [  640/ 2237]\n",
      "loss: 0.204616  [ 1280/ 2237]\n",
      "loss: 0.138371  [ 1920/ 2237]\n",
      "loss: 0.056967  [    0/ 2237]\n",
      "loss: 0.187359  [  640/ 2237]\n",
      "loss: 0.104316  [ 1280/ 2237]\n",
      "loss: 0.176335  [ 1920/ 2237]\n",
      "loss: 0.150094  [    0/ 2237]\n",
      "loss: 0.202475  [  640/ 2237]\n",
      "loss: 0.173086  [ 1280/ 2237]\n",
      "loss: 0.166357  [ 1920/ 2237]\n",
      "loss: 0.070650  [    0/ 2237]\n",
      "loss: 0.245990  [  640/ 2237]\n",
      "loss: 0.126229  [ 1280/ 2237]\n",
      "loss: 0.214604  [ 1920/ 2237]\n",
      "loss: 0.085464  [    0/ 2237]\n",
      "loss: 0.100973  [  640/ 2237]\n",
      "loss: 0.149277  [ 1280/ 2237]\n",
      "loss: 0.031534  [ 1920/ 2237]\n",
      "loss: 0.135541  [    0/ 2237]\n",
      "loss: 0.151287  [  640/ 2237]\n",
      "loss: 0.097775  [ 1280/ 2237]\n",
      "loss: 0.095230  [ 1920/ 2237]\n",
      "loss: 0.021847  [    0/ 2237]\n",
      "loss: 0.068062  [  640/ 2237]\n",
      "loss: 0.101371  [ 1280/ 2237]\n",
      "loss: 0.103997  [ 1920/ 2237]\n",
      "loss: 0.044963  [    0/ 2237]\n",
      "loss: 0.096554  [  640/ 2237]\n",
      "loss: 0.092754  [ 1280/ 2237]\n",
      "loss: 0.046611  [ 1920/ 2237]\n",
      "loss: 0.067186  [    0/ 2237]\n",
      "loss: 0.045632  [  640/ 2237]\n",
      "loss: 0.086632  [ 1280/ 2237]\n",
      "loss: 0.021098  [ 1920/ 2237]\n",
      "loss: 0.057025  [    0/ 2237]\n",
      "loss: 0.128665  [  640/ 2237]\n",
      "loss: 0.128113  [ 1280/ 2237]\n",
      "loss: 0.399699  [ 1920/ 2237]\n",
      "loss: 0.046634  [    0/ 2237]\n",
      "loss: 0.028315  [  640/ 2237]\n",
      "loss: 0.030388  [ 1280/ 2237]\n",
      "loss: 0.115812  [ 1920/ 2237]\n",
      "loss: 0.267054  [    0/ 2237]\n",
      "loss: 0.083495  [  640/ 2237]\n",
      "loss: 0.158009  [ 1280/ 2237]\n",
      "loss: 0.074667  [ 1920/ 2237]\n",
      "loss: 0.048948  [    0/ 2237]\n",
      "loss: 0.074884  [  640/ 2237]\n",
      "loss: 0.084003  [ 1280/ 2237]\n",
      "loss: 0.035355  [ 1920/ 2237]\n",
      "loss: 0.205511  [    0/ 2237]\n",
      "loss: 0.247628  [  640/ 2237]\n",
      "loss: 0.080792  [ 1280/ 2237]\n",
      "loss: 0.303939  [ 1920/ 2237]\n",
      "loss: 0.118425  [    0/ 2237]\n",
      "loss: 0.140369  [  640/ 2237]\n",
      "loss: 0.070768  [ 1280/ 2237]\n",
      "loss: 0.056364  [ 1920/ 2237]\n",
      "loss: 0.027732  [    0/ 2237]\n",
      "loss: 0.043323  [  640/ 2237]\n",
      "loss: 0.057071  [ 1280/ 2237]\n",
      "loss: 0.566594  [ 1920/ 2237]\n",
      "loss: 0.043323  [    0/ 2237]\n",
      "loss: 0.033122  [  640/ 2237]\n",
      "loss: 0.042673  [ 1280/ 2237]\n",
      "loss: 0.139641  [ 1920/ 2237]\n",
      "loss: 0.010062  [    0/ 2237]\n",
      "loss: 0.063897  [  640/ 2237]\n",
      "loss: 0.340454  [ 1280/ 2237]\n",
      "loss: 0.201671  [ 1920/ 2237]\n",
      "loss: 0.026882  [    0/ 2237]\n",
      "loss: 0.036582  [  640/ 2237]\n",
      "loss: 0.016329  [ 1280/ 2237]\n",
      "loss: 0.011701  [ 1920/ 2237]\n",
      "loss: 0.005547  [    0/ 2237]\n",
      "loss: 0.025454  [  640/ 2237]\n",
      "loss: 0.007843  [ 1280/ 2237]\n",
      "loss: 0.025951  [ 1920/ 2237]\n",
      "loss: 0.095830  [    0/ 2237]\n",
      "loss: 0.021334  [  640/ 2237]\n",
      "loss: 0.007687  [ 1280/ 2237]\n",
      "loss: 0.053404  [ 1920/ 2237]\n",
      "loss: 0.005088  [    0/ 2237]\n",
      "loss: 0.050756  [  640/ 2237]\n",
      "loss: 0.042375  [ 1280/ 2237]\n",
      "loss: 0.036511  [ 1920/ 2237]\n",
      "loss: 0.007816  [    0/ 2237]\n",
      "loss: 0.015423  [  640/ 2237]\n",
      "loss: 0.021188  [ 1280/ 2237]\n",
      "loss: 0.007511  [ 1920/ 2237]\n",
      "loss: 0.005717  [    0/ 2237]\n",
      "loss: 0.045724  [  640/ 2237]\n",
      "loss: 0.053108  [ 1280/ 2237]\n",
      "loss: 0.020933  [ 1920/ 2237]\n",
      "loss: 0.007183  [    0/ 2237]\n",
      "loss: 0.007951  [  640/ 2237]\n",
      "loss: 0.053427  [ 1280/ 2237]\n",
      "loss: 0.004332  [ 1920/ 2237]\n",
      "loss: 0.112847  [    0/ 2237]\n",
      "loss: 0.120172  [  640/ 2237]\n",
      "loss: 0.053027  [ 1280/ 2237]\n",
      "loss: 0.018980  [ 1920/ 2237]\n",
      "loss: 0.035071  [    0/ 2237]\n",
      "loss: 0.004283  [  640/ 2237]\n",
      "loss: 0.104092  [ 1280/ 2237]\n",
      "loss: 0.298681  [ 1920/ 2237]\n",
      "loss: 0.073977  [    0/ 2237]\n",
      "loss: 0.060139  [  640/ 2237]\n",
      "loss: 0.028123  [ 1280/ 2237]\n",
      "loss: 0.051663  [ 1920/ 2237]\n",
      "loss: 0.022289  [    0/ 2237]\n",
      "loss: 0.000977  [  640/ 2237]\n",
      "loss: 0.026793  [ 1280/ 2237]\n",
      "loss: 0.033246  [ 1920/ 2237]\n",
      "loss: 0.003853  [    0/ 2237]\n",
      "loss: 0.025531  [  640/ 2237]\n",
      "loss: 0.021046  [ 1280/ 2237]\n",
      "loss: 0.099989  [ 1920/ 2237]\n",
      "loss: 0.023585  [    0/ 2237]\n",
      "loss: 0.021993  [  640/ 2237]\n",
      "loss: 0.118790  [ 1280/ 2237]\n",
      "loss: 0.042938  [ 1920/ 2237]\n",
      "Validation Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.918044 \n",
      "\n",
      "\n",
      "loss: 3.242944  [    0/ 2237]\n",
      "loss: 2.710520  [  640/ 2237]\n",
      "loss: 2.676924  [ 1280/ 2237]\n",
      "loss: 2.602663  [ 1920/ 2237]\n",
      "loss: 2.365761  [    0/ 2237]\n",
      "loss: 2.156774  [  640/ 2237]\n",
      "loss: 2.076928  [ 1280/ 2237]\n",
      "loss: 1.719947  [ 1920/ 2237]\n",
      "loss: 1.827072  [    0/ 2237]\n",
      "loss: 1.862631  [  640/ 2237]\n",
      "loss: 1.896348  [ 1280/ 2237]\n",
      "loss: 1.306235  [ 1920/ 2237]\n",
      "loss: 1.475458  [    0/ 2237]\n",
      "loss: 1.494171  [  640/ 2237]\n",
      "loss: 1.414423  [ 1280/ 2237]\n",
      "loss: 1.486702  [ 1920/ 2237]\n",
      "loss: 1.323845  [    0/ 2237]\n",
      "loss: 1.047175  [  640/ 2237]\n",
      "loss: 1.214775  [ 1280/ 2237]\n",
      "loss: 1.392162  [ 1920/ 2237]\n",
      "loss: 0.975522  [    0/ 2237]\n",
      "loss: 1.471127  [  640/ 2237]\n",
      "loss: 1.035617  [ 1280/ 2237]\n",
      "loss: 1.165147  [ 1920/ 2237]\n",
      "loss: 1.032886  [    0/ 2237]\n",
      "loss: 1.003296  [  640/ 2237]\n",
      "loss: 0.849108  [ 1280/ 2237]\n",
      "loss: 0.869659  [ 1920/ 2237]\n",
      "loss: 0.952947  [    0/ 2237]\n",
      "loss: 0.787657  [  640/ 2237]\n",
      "loss: 0.843840  [ 1280/ 2237]\n",
      "loss: 0.816771  [ 1920/ 2237]\n",
      "loss: 0.657058  [    0/ 2237]\n",
      "loss: 0.575694  [  640/ 2237]\n",
      "loss: 0.702066  [ 1280/ 2237]\n",
      "loss: 0.612398  [ 1920/ 2237]\n",
      "loss: 0.720327  [    0/ 2237]\n",
      "loss: 0.598366  [  640/ 2237]\n",
      "loss: 0.585125  [ 1280/ 2237]\n",
      "loss: 0.557752  [ 1920/ 2237]\n",
      "loss: 0.716013  [    0/ 2237]\n",
      "loss: 0.668027  [  640/ 2237]\n",
      "loss: 0.634916  [ 1280/ 2237]\n",
      "loss: 0.521911  [ 1920/ 2237]\n",
      "loss: 0.476684  [    0/ 2237]\n",
      "loss: 0.316499  [  640/ 2237]\n",
      "loss: 0.568113  [ 1280/ 2237]\n",
      "loss: 0.591654  [ 1920/ 2237]\n",
      "loss: 0.332454  [    0/ 2237]\n",
      "loss: 0.458095  [  640/ 2237]\n",
      "loss: 0.504790  [ 1280/ 2237]\n",
      "loss: 0.467397  [ 1920/ 2237]\n",
      "loss: 0.366052  [    0/ 2237]\n",
      "loss: 0.365432  [  640/ 2237]\n",
      "loss: 0.434087  [ 1280/ 2237]\n",
      "loss: 0.319515  [ 1920/ 2237]\n",
      "loss: 0.369280  [    0/ 2237]\n",
      "loss: 0.440838  [  640/ 2237]\n",
      "loss: 0.400773  [ 1280/ 2237]\n",
      "loss: 0.230062  [ 1920/ 2237]\n",
      "loss: 0.164846  [    0/ 2237]\n",
      "loss: 0.415495  [  640/ 2237]\n",
      "loss: 0.313419  [ 1280/ 2237]\n",
      "loss: 0.597152  [ 1920/ 2237]\n",
      "loss: 0.266538  [    0/ 2237]\n",
      "loss: 0.258082  [  640/ 2237]\n",
      "loss: 0.252289  [ 1280/ 2237]\n",
      "loss: 0.343370  [ 1920/ 2237]\n",
      "loss: 0.198752  [    0/ 2237]\n",
      "loss: 0.280897  [  640/ 2237]\n",
      "loss: 0.290500  [ 1280/ 2237]\n",
      "loss: 0.189858  [ 1920/ 2237]\n",
      "loss: 0.193215  [    0/ 2237]\n",
      "loss: 0.316504  [  640/ 2237]\n",
      "loss: 0.184191  [ 1280/ 2237]\n",
      "loss: 0.339543  [ 1920/ 2237]\n",
      "loss: 0.339053  [    0/ 2237]\n",
      "loss: 0.191441  [  640/ 2237]\n",
      "loss: 0.164480  [ 1280/ 2237]\n",
      "loss: 0.184526  [ 1920/ 2237]\n",
      "loss: 0.197293  [    0/ 2237]\n",
      "loss: 0.132979  [  640/ 2237]\n",
      "loss: 0.137696  [ 1280/ 2237]\n",
      "loss: 0.171640  [ 1920/ 2237]\n",
      "loss: 0.126852  [    0/ 2237]\n",
      "loss: 0.170680  [  640/ 2237]\n",
      "loss: 0.189724  [ 1280/ 2237]\n",
      "loss: 0.229076  [ 1920/ 2237]\n",
      "loss: 0.131958  [    0/ 2237]\n",
      "loss: 0.093567  [  640/ 2237]\n",
      "loss: 0.144618  [ 1280/ 2237]\n",
      "loss: 0.102313  [ 1920/ 2237]\n",
      "loss: 0.160306  [    0/ 2237]\n",
      "loss: 0.136761  [  640/ 2237]\n",
      "loss: 0.192767  [ 1280/ 2237]\n",
      "loss: 0.226372  [ 1920/ 2237]\n",
      "loss: 0.102471  [    0/ 2237]\n",
      "loss: 0.186050  [  640/ 2237]\n",
      "loss: 0.164526  [ 1280/ 2237]\n",
      "loss: 0.197515  [ 1920/ 2237]\n",
      "loss: 0.119576  [    0/ 2237]\n",
      "loss: 0.177886  [  640/ 2237]\n",
      "loss: 0.288648  [ 1280/ 2237]\n",
      "loss: 0.125363  [ 1920/ 2237]\n",
      "loss: 0.081994  [    0/ 2237]\n",
      "loss: 0.166247  [  640/ 2237]\n",
      "loss: 0.136539  [ 1280/ 2237]\n",
      "loss: 0.240296  [ 1920/ 2237]\n",
      "loss: 0.232292  [    0/ 2237]\n",
      "loss: 0.191357  [  640/ 2237]\n",
      "loss: 0.072588  [ 1280/ 2237]\n",
      "loss: 0.088141  [ 1920/ 2237]\n",
      "loss: 0.139907  [    0/ 2237]\n",
      "loss: 0.094169  [  640/ 2237]\n",
      "loss: 0.050433  [ 1280/ 2237]\n",
      "loss: 0.028099  [ 1920/ 2237]\n",
      "loss: 0.079520  [    0/ 2237]\n",
      "loss: 0.054608  [  640/ 2237]\n",
      "loss: 0.056339  [ 1280/ 2237]\n",
      "loss: 0.052669  [ 1920/ 2237]\n",
      "loss: 0.057819  [    0/ 2237]\n",
      "loss: 0.030085  [  640/ 2237]\n",
      "loss: 0.026573  [ 1280/ 2237]\n",
      "loss: 0.029864  [ 1920/ 2237]\n",
      "loss: 0.054339  [    0/ 2237]\n",
      "loss: 0.077241  [  640/ 2237]\n",
      "loss: 0.042940  [ 1280/ 2237]\n",
      "loss: 0.170925  [ 1920/ 2237]\n",
      "loss: 0.196141  [    0/ 2237]\n",
      "loss: 0.041216  [  640/ 2237]\n",
      "loss: 0.224049  [ 1280/ 2237]\n",
      "loss: 0.156087  [ 1920/ 2237]\n",
      "loss: 0.027480  [    0/ 2237]\n",
      "loss: 0.153319  [  640/ 2237]\n",
      "loss: 0.072609  [ 1280/ 2237]\n",
      "loss: 0.052176  [ 1920/ 2237]\n",
      "loss: 0.134548  [    0/ 2237]\n",
      "loss: 0.086230  [  640/ 2237]\n",
      "loss: 0.020093  [ 1280/ 2237]\n",
      "loss: 0.037558  [ 1920/ 2237]\n",
      "loss: 0.033840  [    0/ 2237]\n",
      "loss: 0.031774  [  640/ 2237]\n",
      "loss: 0.022485  [ 1280/ 2237]\n",
      "loss: 0.052032  [ 1920/ 2237]\n",
      "loss: 0.052175  [    0/ 2237]\n",
      "loss: 0.111443  [  640/ 2237]\n",
      "loss: 0.089873  [ 1280/ 2237]\n",
      "loss: 0.056131  [ 1920/ 2237]\n",
      "loss: 0.009469  [    0/ 2237]\n",
      "loss: 0.013917  [  640/ 2237]\n",
      "loss: 0.049737  [ 1280/ 2237]\n",
      "loss: 0.167061  [ 1920/ 2237]\n",
      "loss: 0.032128  [    0/ 2237]\n",
      "loss: 0.008355  [  640/ 2237]\n",
      "loss: 0.086969  [ 1280/ 2237]\n",
      "loss: 0.312301  [ 1920/ 2237]\n",
      "loss: 0.030727  [    0/ 2237]\n",
      "loss: 0.091741  [  640/ 2237]\n",
      "loss: 0.136988  [ 1280/ 2237]\n",
      "loss: 0.082551  [ 1920/ 2237]\n",
      "loss: 0.011379  [    0/ 2237]\n",
      "loss: 0.035314  [  640/ 2237]\n",
      "loss: 0.098020  [ 1280/ 2237]\n",
      "loss: 0.192319  [ 1920/ 2237]\n",
      "loss: 0.013391  [    0/ 2237]\n",
      "loss: 0.059334  [  640/ 2237]\n",
      "loss: 0.034865  [ 1280/ 2237]\n",
      "loss: 0.018180  [ 1920/ 2237]\n",
      "loss: 0.191412  [    0/ 2237]\n",
      "loss: 0.011096  [  640/ 2237]\n",
      "loss: 0.015384  [ 1280/ 2237]\n",
      "loss: 0.034635  [ 1920/ 2237]\n",
      "loss: 0.004902  [    0/ 2237]\n",
      "loss: 0.026528  [  640/ 2237]\n",
      "loss: 0.090191  [ 1280/ 2237]\n",
      "loss: 0.104750  [ 1920/ 2237]\n",
      "loss: 0.057616  [    0/ 2237]\n",
      "loss: 0.316087  [  640/ 2237]\n",
      "loss: 0.128364  [ 1280/ 2237]\n",
      "loss: 0.351330  [ 1920/ 2237]\n",
      "loss: 0.133999  [    0/ 2237]\n",
      "loss: 0.153410  [  640/ 2237]\n",
      "loss: 0.033230  [ 1280/ 2237]\n",
      "loss: 0.075855  [ 1920/ 2237]\n",
      "loss: 0.100867  [    0/ 2237]\n",
      "loss: 0.173666  [  640/ 2237]\n",
      "loss: 0.071085  [ 1280/ 2237]\n",
      "loss: 0.023653  [ 1920/ 2237]\n",
      "loss: 0.015515  [    0/ 2237]\n",
      "loss: 0.076258  [  640/ 2237]\n",
      "loss: 0.056500  [ 1280/ 2237]\n",
      "loss: 0.051843  [ 1920/ 2237]\n",
      "loss: 0.037841  [    0/ 2237]\n",
      "loss: 0.018306  [  640/ 2237]\n",
      "loss: 0.006208  [ 1280/ 2237]\n",
      "loss: 0.016606  [ 1920/ 2237]\n",
      "loss: 0.019484  [    0/ 2237]\n",
      "loss: 0.149916  [  640/ 2237]\n",
      "loss: 0.021056  [ 1280/ 2237]\n",
      "loss: 0.051489  [ 1920/ 2237]\n",
      "Validation Error: \n",
      " Accuracy: 84.3%, Avg loss: 0.694548 \n",
      "\n",
      "\n",
      "loss: 3.349701  [    0/ 2237]\n",
      "loss: 2.696804  [  640/ 2237]\n",
      "loss: 2.654781  [ 1280/ 2237]\n",
      "loss: 2.298437  [ 1920/ 2237]\n",
      "loss: 2.281935  [    0/ 2237]\n",
      "loss: 2.133486  [  640/ 2237]\n",
      "loss: 2.148412  [ 1280/ 2237]\n",
      "loss: 1.940945  [ 1920/ 2237]\n",
      "loss: 1.874013  [    0/ 2237]\n",
      "loss: 1.762312  [  640/ 2237]\n",
      "loss: 1.705387  [ 1280/ 2237]\n",
      "loss: 1.533777  [ 1920/ 2237]\n",
      "loss: 1.612392  [    0/ 2237]\n",
      "loss: 1.630794  [  640/ 2237]\n",
      "loss: 1.533854  [ 1280/ 2237]\n",
      "loss: 1.328426  [ 1920/ 2237]\n",
      "loss: 1.268395  [    0/ 2237]\n",
      "loss: 1.341201  [  640/ 2237]\n",
      "loss: 1.411429  [ 1280/ 2237]\n",
      "loss: 1.358945  [ 1920/ 2237]\n",
      "loss: 1.265690  [    0/ 2237]\n",
      "loss: 1.024184  [  640/ 2237]\n",
      "loss: 0.858198  [ 1280/ 2237]\n",
      "loss: 1.098818  [ 1920/ 2237]\n",
      "loss: 1.034508  [    0/ 2237]\n",
      "loss: 0.997533  [  640/ 2237]\n",
      "loss: 1.006580  [ 1280/ 2237]\n",
      "loss: 0.965695  [ 1920/ 2237]\n",
      "loss: 0.890463  [    0/ 2237]\n",
      "loss: 0.940713  [  640/ 2237]\n",
      "loss: 0.794116  [ 1280/ 2237]\n",
      "loss: 0.898339  [ 1920/ 2237]\n",
      "loss: 0.720472  [    0/ 2237]\n",
      "loss: 0.695736  [  640/ 2237]\n",
      "loss: 0.701873  [ 1280/ 2237]\n",
      "loss: 0.686698  [ 1920/ 2237]\n",
      "loss: 0.513337  [    0/ 2237]\n",
      "loss: 0.756174  [  640/ 2237]\n",
      "loss: 0.627632  [ 1280/ 2237]\n",
      "loss: 0.725145  [ 1920/ 2237]\n",
      "loss: 0.763756  [    0/ 2237]\n",
      "loss: 0.543452  [  640/ 2237]\n",
      "loss: 0.523776  [ 1280/ 2237]\n",
      "loss: 0.461880  [ 1920/ 2237]\n",
      "loss: 0.450752  [    0/ 2237]\n",
      "loss: 0.392678  [  640/ 2237]\n",
      "loss: 0.693290  [ 1280/ 2237]\n",
      "loss: 0.427224  [ 1920/ 2237]\n",
      "loss: 0.536744  [    0/ 2237]\n",
      "loss: 0.508922  [  640/ 2237]\n",
      "loss: 0.345286  [ 1280/ 2237]\n",
      "loss: 0.473730  [ 1920/ 2237]\n",
      "loss: 0.287132  [    0/ 2237]\n",
      "loss: 0.232982  [  640/ 2237]\n",
      "loss: 0.508466  [ 1280/ 2237]\n",
      "loss: 0.486138  [ 1920/ 2237]\n",
      "loss: 0.313596  [    0/ 2237]\n",
      "loss: 0.398210  [  640/ 2237]\n",
      "loss: 0.400486  [ 1280/ 2237]\n",
      "loss: 0.315101  [ 1920/ 2237]\n",
      "loss: 0.338115  [    0/ 2237]\n",
      "loss: 0.167490  [  640/ 2237]\n",
      "loss: 0.293105  [ 1280/ 2237]\n",
      "loss: 0.320076  [ 1920/ 2237]\n",
      "loss: 0.171659  [    0/ 2237]\n",
      "loss: 0.178815  [  640/ 2237]\n",
      "loss: 0.158457  [ 1280/ 2237]\n",
      "loss: 0.248901  [ 1920/ 2237]\n",
      "loss: 0.303756  [    0/ 2237]\n",
      "loss: 0.139708  [  640/ 2237]\n",
      "loss: 0.181118  [ 1280/ 2237]\n",
      "loss: 0.255102  [ 1920/ 2237]\n",
      "loss: 0.339109  [    0/ 2237]\n",
      "loss: 0.267057  [  640/ 2237]\n",
      "loss: 0.194934  [ 1280/ 2237]\n",
      "loss: 0.137253  [ 1920/ 2237]\n",
      "loss: 0.238329  [    0/ 2237]\n",
      "loss: 0.282276  [  640/ 2237]\n",
      "loss: 0.240439  [ 1280/ 2237]\n",
      "loss: 0.118161  [ 1920/ 2237]\n",
      "loss: 0.257056  [    0/ 2237]\n",
      "loss: 0.190872  [  640/ 2237]\n",
      "loss: 0.306098  [ 1280/ 2237]\n",
      "loss: 0.383781  [ 1920/ 2237]\n",
      "loss: 0.255767  [    0/ 2237]\n",
      "loss: 0.330696  [  640/ 2237]\n",
      "loss: 0.231877  [ 1280/ 2237]\n",
      "loss: 0.084332  [ 1920/ 2237]\n",
      "loss: 0.068052  [    0/ 2237]\n",
      "loss: 0.257346  [  640/ 2237]\n",
      "loss: 0.205882  [ 1280/ 2237]\n",
      "loss: 0.236314  [ 1920/ 2237]\n",
      "loss: 0.081174  [    0/ 2237]\n",
      "loss: 0.078268  [  640/ 2237]\n",
      "loss: 0.082134  [ 1280/ 2237]\n",
      "loss: 0.226339  [ 1920/ 2237]\n",
      "loss: 0.060551  [    0/ 2237]\n",
      "loss: 0.116590  [  640/ 2237]\n",
      "loss: 0.153324  [ 1280/ 2237]\n",
      "loss: 0.118993  [ 1920/ 2237]\n",
      "loss: 0.060016  [    0/ 2237]\n",
      "loss: 0.075095  [  640/ 2237]\n",
      "loss: 0.237332  [ 1280/ 2237]\n",
      "loss: 0.029467  [ 1920/ 2237]\n",
      "loss: 0.151621  [    0/ 2237]\n",
      "loss: 0.148959  [  640/ 2237]\n",
      "loss: 0.172339  [ 1280/ 2237]\n",
      "loss: 0.134224  [ 1920/ 2237]\n",
      "loss: 0.032140  [    0/ 2237]\n",
      "loss: 0.103117  [  640/ 2237]\n",
      "loss: 0.056351  [ 1280/ 2237]\n",
      "loss: 0.063436  [ 1920/ 2237]\n",
      "loss: 0.020405  [    0/ 2237]\n",
      "loss: 0.069011  [  640/ 2237]\n",
      "loss: 0.115957  [ 1280/ 2237]\n",
      "loss: 0.147357  [ 1920/ 2237]\n",
      "loss: 0.066626  [    0/ 2237]\n",
      "loss: 0.061249  [  640/ 2237]\n",
      "loss: 0.061538  [ 1280/ 2237]\n",
      "loss: 0.253619  [ 1920/ 2237]\n",
      "loss: 0.056010  [    0/ 2237]\n",
      "loss: 0.034650  [  640/ 2237]\n",
      "loss: 0.014137  [ 1280/ 2237]\n",
      "loss: 0.086349  [ 1920/ 2237]\n",
      "loss: 0.127081  [    0/ 2237]\n",
      "loss: 0.066647  [  640/ 2237]\n",
      "loss: 0.127664  [ 1280/ 2237]\n",
      "loss: 0.154894  [ 1920/ 2237]\n",
      "loss: 0.042667  [    0/ 2237]\n",
      "loss: 0.074519  [  640/ 2237]\n",
      "loss: 0.049905  [ 1280/ 2237]\n",
      "loss: 0.108772  [ 1920/ 2237]\n",
      "loss: 0.321707  [    0/ 2237]\n",
      "loss: 0.196249  [  640/ 2237]\n",
      "loss: 0.174810  [ 1280/ 2237]\n",
      "loss: 0.057783  [ 1920/ 2237]\n",
      "loss: 0.193100  [    0/ 2237]\n",
      "loss: 0.053607  [  640/ 2237]\n",
      "loss: 0.391593  [ 1280/ 2237]\n",
      "loss: 0.103717  [ 1920/ 2237]\n",
      "loss: 0.023882  [    0/ 2237]\n",
      "loss: 0.033933  [  640/ 2237]\n",
      "loss: 0.299208  [ 1280/ 2237]\n",
      "loss: 0.134335  [ 1920/ 2237]\n",
      "loss: 0.130409  [    0/ 2237]\n",
      "loss: 0.057340  [  640/ 2237]\n",
      "loss: 0.157689  [ 1280/ 2237]\n",
      "loss: 0.041432  [ 1920/ 2237]\n",
      "loss: 0.036025  [    0/ 2237]\n",
      "loss: 0.007439  [  640/ 2237]\n",
      "loss: 0.050933  [ 1280/ 2237]\n",
      "loss: 0.007897  [ 1920/ 2237]\n",
      "loss: 0.066377  [    0/ 2237]\n",
      "loss: 0.112460  [  640/ 2237]\n",
      "loss: 0.024481  [ 1280/ 2237]\n",
      "loss: 0.005367  [ 1920/ 2237]\n",
      "loss: 0.098229  [    0/ 2237]\n",
      "loss: 0.063553  [  640/ 2237]\n",
      "loss: 0.064456  [ 1280/ 2237]\n",
      "loss: 0.081002  [ 1920/ 2237]\n",
      "loss: 0.035689  [    0/ 2237]\n",
      "loss: 0.054654  [  640/ 2237]\n",
      "loss: 0.025840  [ 1280/ 2237]\n",
      "loss: 0.080751  [ 1920/ 2237]\n",
      "loss: 0.024685  [    0/ 2237]\n",
      "loss: 0.006499  [  640/ 2237]\n",
      "loss: 0.047753  [ 1280/ 2237]\n",
      "loss: 0.009465  [ 1920/ 2237]\n",
      "loss: 0.028439  [    0/ 2237]\n",
      "loss: 0.002813  [  640/ 2237]\n",
      "loss: 0.010392  [ 1280/ 2237]\n",
      "loss: 0.001288  [ 1920/ 2237]\n",
      "loss: 0.003844  [    0/ 2237]\n",
      "loss: 0.005170  [  640/ 2237]\n",
      "loss: 0.000510  [ 1280/ 2237]\n",
      "loss: 0.014492  [ 1920/ 2237]\n",
      "loss: 0.001801  [    0/ 2237]\n",
      "loss: 0.001000  [  640/ 2237]\n",
      "loss: 0.005715  [ 1280/ 2237]\n",
      "loss: 0.001756  [ 1920/ 2237]\n",
      "loss: 0.002094  [    0/ 2237]\n",
      "loss: 0.022006  [  640/ 2237]\n",
      "loss: 0.002231  [ 1280/ 2237]\n",
      "loss: 0.001073  [ 1920/ 2237]\n",
      "loss: 0.003970  [    0/ 2237]\n",
      "loss: 0.001305  [  640/ 2237]\n",
      "loss: 0.015008  [ 1280/ 2237]\n",
      "loss: 0.019072  [ 1920/ 2237]\n",
      "loss: 0.102528  [    0/ 2237]\n",
      "loss: 0.180416  [  640/ 2237]\n",
      "loss: 0.164003  [ 1280/ 2237]\n",
      "loss: 0.018613  [ 1920/ 2237]\n",
      "loss: 0.096548  [    0/ 2237]\n",
      "loss: 0.190447  [  640/ 2237]\n",
      "loss: 0.024444  [ 1280/ 2237]\n",
      "loss: 0.026016  [ 1920/ 2237]\n",
      "loss: 0.014808  [    0/ 2237]\n",
      "loss: 0.189954  [  640/ 2237]\n",
      "loss: 0.319283  [ 1280/ 2237]\n",
      "loss: 0.080076  [ 1920/ 2237]\n",
      "Validation Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.826431 \n",
      "\n",
      "\n",
      "loss: 3.165247  [    0/ 2237]\n",
      "loss: 2.742490  [  640/ 2237]\n",
      "loss: 2.515352  [ 1280/ 2237]\n",
      "loss: 2.396060  [ 1920/ 2237]\n",
      "loss: 2.260557  [    0/ 2237]\n",
      "loss: 1.944741  [  640/ 2237]\n",
      "loss: 1.906381  [ 1280/ 2237]\n",
      "loss: 1.793376  [ 1920/ 2237]\n",
      "loss: 1.861009  [    0/ 2237]\n",
      "loss: 1.449930  [  640/ 2237]\n",
      "loss: 1.767117  [ 1280/ 2237]\n",
      "loss: 1.593970  [ 1920/ 2237]\n",
      "loss: 1.348040  [    0/ 2237]\n",
      "loss: 1.266430  [  640/ 2237]\n",
      "loss: 1.363749  [ 1280/ 2237]\n",
      "loss: 1.268083  [ 1920/ 2237]\n",
      "loss: 1.392201  [    0/ 2237]\n",
      "loss: 1.389672  [  640/ 2237]\n",
      "loss: 1.330066  [ 1280/ 2237]\n",
      "loss: 1.263508  [ 1920/ 2237]\n",
      "loss: 1.121187  [    0/ 2237]\n",
      "loss: 0.965565  [  640/ 2237]\n",
      "loss: 1.335486  [ 1280/ 2237]\n",
      "loss: 1.313208  [ 1920/ 2237]\n",
      "loss: 0.943577  [    0/ 2237]\n",
      "loss: 0.899736  [  640/ 2237]\n",
      "loss: 0.964577  [ 1280/ 2237]\n",
      "loss: 1.046537  [ 1920/ 2237]\n",
      "loss: 0.857642  [    0/ 2237]\n",
      "loss: 1.012224  [  640/ 2237]\n",
      "loss: 0.722377  [ 1280/ 2237]\n",
      "loss: 0.811254  [ 1920/ 2237]\n",
      "loss: 0.868277  [    0/ 2237]\n",
      "loss: 0.591270  [  640/ 2237]\n",
      "loss: 0.795830  [ 1280/ 2237]\n",
      "loss: 0.550453  [ 1920/ 2237]\n",
      "loss: 0.770409  [    0/ 2237]\n",
      "loss: 0.784062  [  640/ 2237]\n",
      "loss: 0.818585  [ 1280/ 2237]\n",
      "loss: 0.710584  [ 1920/ 2237]\n",
      "loss: 0.574552  [    0/ 2237]\n",
      "loss: 0.643658  [  640/ 2237]\n",
      "loss: 0.478235  [ 1280/ 2237]\n",
      "loss: 0.516216  [ 1920/ 2237]\n",
      "loss: 0.749982  [    0/ 2237]\n",
      "loss: 0.360928  [  640/ 2237]\n",
      "loss: 0.482738  [ 1280/ 2237]\n",
      "loss: 0.551809  [ 1920/ 2237]\n",
      "loss: 0.495859  [    0/ 2237]\n",
      "loss: 0.391786  [  640/ 2237]\n",
      "loss: 0.514610  [ 1280/ 2237]\n",
      "loss: 0.582277  [ 1920/ 2237]\n",
      "loss: 0.498531  [    0/ 2237]\n",
      "loss: 0.590987  [  640/ 2237]\n",
      "loss: 0.245335  [ 1280/ 2237]\n",
      "loss: 0.301181  [ 1920/ 2237]\n",
      "loss: 0.235267  [    0/ 2237]\n",
      "loss: 0.222865  [  640/ 2237]\n",
      "loss: 0.291758  [ 1280/ 2237]\n",
      "loss: 0.167665  [ 1920/ 2237]\n",
      "loss: 0.242313  [    0/ 2237]\n",
      "loss: 0.281239  [  640/ 2237]\n",
      "loss: 0.497003  [ 1280/ 2237]\n",
      "loss: 0.385349  [ 1920/ 2237]\n",
      "loss: 0.078520  [    0/ 2237]\n",
      "loss: 0.245523  [  640/ 2237]\n",
      "loss: 0.411503  [ 1280/ 2237]\n",
      "loss: 0.240239  [ 1920/ 2237]\n",
      "loss: 0.256582  [    0/ 2237]\n",
      "loss: 0.192771  [  640/ 2237]\n",
      "loss: 0.349772  [ 1280/ 2237]\n",
      "loss: 0.410206  [ 1920/ 2237]\n",
      "loss: 0.382342  [    0/ 2237]\n",
      "loss: 0.184636  [  640/ 2237]\n",
      "loss: 0.145904  [ 1280/ 2237]\n",
      "loss: 0.239826  [ 1920/ 2237]\n",
      "loss: 0.350372  [    0/ 2237]\n",
      "loss: 0.250499  [  640/ 2237]\n",
      "loss: 0.147337  [ 1280/ 2237]\n",
      "loss: 0.207388  [ 1920/ 2237]\n",
      "loss: 0.501339  [    0/ 2237]\n",
      "loss: 0.188291  [  640/ 2237]\n",
      "loss: 0.244560  [ 1280/ 2237]\n",
      "loss: 0.380310  [ 1920/ 2237]\n",
      "loss: 0.373835  [    0/ 2237]\n",
      "loss: 0.218574  [  640/ 2237]\n",
      "loss: 0.103189  [ 1280/ 2237]\n",
      "loss: 0.128841  [ 1920/ 2237]\n",
      "loss: 0.158545  [    0/ 2237]\n",
      "loss: 0.081952  [  640/ 2237]\n",
      "loss: 0.136961  [ 1280/ 2237]\n",
      "loss: 0.122898  [ 1920/ 2237]\n",
      "loss: 0.075424  [    0/ 2237]\n",
      "loss: 0.089293  [  640/ 2237]\n",
      "loss: 0.117722  [ 1280/ 2237]\n",
      "loss: 0.068036  [ 1920/ 2237]\n",
      "loss: 0.064220  [    0/ 2237]\n",
      "loss: 0.131262  [  640/ 2237]\n",
      "loss: 0.178143  [ 1280/ 2237]\n",
      "loss: 0.177786  [ 1920/ 2237]\n",
      "loss: 0.117890  [    0/ 2237]\n",
      "loss: 0.045468  [  640/ 2237]\n",
      "loss: 0.047038  [ 1280/ 2237]\n",
      "loss: 0.117161  [ 1920/ 2237]\n",
      "loss: 0.046059  [    0/ 2237]\n",
      "loss: 0.174967  [  640/ 2237]\n",
      "loss: 0.169038  [ 1280/ 2237]\n",
      "loss: 0.071119  [ 1920/ 2237]\n",
      "loss: 0.096351  [    0/ 2237]\n",
      "loss: 0.077413  [  640/ 2237]\n",
      "loss: 0.078456  [ 1280/ 2237]\n",
      "loss: 0.070572  [ 1920/ 2237]\n",
      "loss: 0.049395  [    0/ 2237]\n",
      "loss: 0.157213  [  640/ 2237]\n",
      "loss: 0.076478  [ 1280/ 2237]\n",
      "loss: 0.169446  [ 1920/ 2237]\n",
      "loss: 0.038274  [    0/ 2237]\n",
      "loss: 0.066364  [  640/ 2237]\n",
      "loss: 0.044219  [ 1280/ 2237]\n",
      "loss: 0.048288  [ 1920/ 2237]\n",
      "loss: 0.123815  [    0/ 2237]\n",
      "loss: 0.107850  [  640/ 2237]\n",
      "loss: 0.193524  [ 1280/ 2237]\n",
      "loss: 0.108312  [ 1920/ 2237]\n",
      "loss: 0.098411  [    0/ 2237]\n",
      "loss: 0.116350  [  640/ 2237]\n",
      "loss: 0.165779  [ 1280/ 2237]\n",
      "loss: 0.130105  [ 1920/ 2237]\n",
      "loss: 0.071728  [    0/ 2237]\n",
      "loss: 0.053218  [  640/ 2237]\n",
      "loss: 0.116939  [ 1280/ 2237]\n",
      "loss: 0.135635  [ 1920/ 2237]\n",
      "loss: 0.083582  [    0/ 2237]\n",
      "loss: 0.029007  [  640/ 2237]\n",
      "loss: 0.009583  [ 1280/ 2237]\n",
      "loss: 0.091331  [ 1920/ 2237]\n",
      "loss: 0.029037  [    0/ 2237]\n",
      "loss: 0.042399  [  640/ 2237]\n",
      "loss: 0.014221  [ 1280/ 2237]\n",
      "loss: 0.061754  [ 1920/ 2237]\n",
      "loss: 0.096311  [    0/ 2237]\n",
      "loss: 0.048420  [  640/ 2237]\n",
      "loss: 0.034559  [ 1280/ 2237]\n",
      "loss: 0.029603  [ 1920/ 2237]\n",
      "loss: 0.052437  [    0/ 2237]\n",
      "loss: 0.076847  [  640/ 2237]\n",
      "loss: 0.056849  [ 1280/ 2237]\n",
      "loss: 0.013744  [ 1920/ 2237]\n",
      "loss: 0.032270  [    0/ 2237]\n",
      "loss: 0.123557  [  640/ 2237]\n",
      "loss: 0.027648  [ 1280/ 2237]\n",
      "loss: 0.024061  [ 1920/ 2237]\n",
      "loss: 0.011724  [    0/ 2237]\n",
      "loss: 0.048120  [  640/ 2237]\n",
      "loss: 0.154727  [ 1280/ 2237]\n",
      "loss: 0.070722  [ 1920/ 2237]\n",
      "loss: 0.009234  [    0/ 2237]\n",
      "loss: 0.035065  [  640/ 2237]\n",
      "loss: 0.049263  [ 1280/ 2237]\n",
      "loss: 0.122559  [ 1920/ 2237]\n",
      "loss: 0.025782  [    0/ 2237]\n",
      "loss: 0.009185  [  640/ 2237]\n",
      "loss: 0.033967  [ 1280/ 2237]\n",
      "loss: 0.055873  [ 1920/ 2237]\n",
      "loss: 0.010340  [    0/ 2237]\n",
      "loss: 0.100774  [  640/ 2237]\n",
      "loss: 0.140962  [ 1280/ 2237]\n",
      "loss: 0.126404  [ 1920/ 2237]\n",
      "loss: 0.146553  [    0/ 2237]\n",
      "loss: 0.132974  [  640/ 2237]\n",
      "loss: 0.143568  [ 1280/ 2237]\n",
      "loss: 0.044286  [ 1920/ 2237]\n",
      "loss: 0.035724  [    0/ 2237]\n",
      "loss: 0.017339  [  640/ 2237]\n",
      "loss: 0.105627  [ 1280/ 2237]\n",
      "loss: 0.010137  [ 1920/ 2237]\n",
      "loss: 0.069237  [    0/ 2237]\n",
      "loss: 0.247177  [  640/ 2237]\n",
      "loss: 0.094002  [ 1280/ 2237]\n",
      "loss: 0.009079  [ 1920/ 2237]\n",
      "loss: 0.075556  [    0/ 2237]\n",
      "loss: 0.021715  [  640/ 2237]\n",
      "loss: 0.056459  [ 1280/ 2237]\n",
      "loss: 0.142420  [ 1920/ 2237]\n",
      "loss: 0.067587  [    0/ 2237]\n",
      "loss: 0.015593  [  640/ 2237]\n",
      "loss: 0.034181  [ 1280/ 2237]\n",
      "loss: 0.007474  [ 1920/ 2237]\n",
      "loss: 0.010388  [    0/ 2237]\n",
      "loss: 0.002290  [  640/ 2237]\n",
      "loss: 0.026840  [ 1280/ 2237]\n",
      "loss: 0.015413  [ 1920/ 2237]\n",
      "loss: 0.003186  [    0/ 2237]\n",
      "loss: 0.054517  [  640/ 2237]\n",
      "loss: 0.044418  [ 1280/ 2237]\n",
      "loss: 0.015868  [ 1920/ 2237]\n",
      "loss: 0.012737  [    0/ 2237]\n",
      "loss: 0.001773  [  640/ 2237]\n",
      "loss: 0.013237  [ 1280/ 2237]\n",
      "loss: 0.000904  [ 1920/ 2237]\n",
      "Validation Error: \n",
      " Accuracy: 83.0%, Avg loss: 0.858222 \n",
      "\n",
      "\n",
      "Average accuracy: 81.39285714285715\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for _ in range(2):\n",
    "    accuracy = main()\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"Average accuracy: {mean(accuracies)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'STD': {'Sensitivity': 0.96045197740113, 'Specificity': 0.9843690430804423, 'Recall': 0.96045197740113, 'Precision': 0.8056872037914692, 'Accuracy': 0.9828571428571429, 'F-score': 0.8762886597938144}, 'WAL': {'Sensitivity': 0.7595628415300546, 'Specificity': 0.9766908674054261, 'Recall': 0.7595628415300546, 'Precision': 0.695, 'Accuracy': 0.9625, 'F-score': 0.7258485639686684}, 'JOG': {'Sensitivity': 0.782608695652174, 'Specificity': 0.9912079510703364, 'Recall': 0.782608695652174, 'Precision': 0.8622754491017964, 'Accuracy': 0.9775, 'F-score': 0.8205128205128205}, 'JUM': {'Sensitivity': 0.8932584269662921, 'Specificity': 0.9893211289092296, 'Recall': 0.8932584269662921, 'Precision': 0.8502673796791443, 'Accuracy': 0.9832142857142857, 'F-score': 0.8712328767123287}, 'STU': {'Sensitivity': 0.6818181818181818, 'Specificity': 0.9880860876249039, 'Recall': 0.6818181818181818, 'Precision': 0.8132530120481928, 'Accuracy': 0.9664285714285714, 'F-score': 0.7417582417582418}, 'STN': {'Sensitivity': 0.7569060773480663, 'Specificity': 0.9801450935471554, 'Recall': 0.7569060773480663, 'Precision': 0.7248677248677249, 'Accuracy': 0.9657142857142857, 'F-score': 0.7405405405405405}, 'SCH': {'Sensitivity': 0.8944723618090452, 'Specificity': 0.9950019223375625, 'Recall': 0.8944723618090452, 'Precision': 0.9319371727748691, 'Accuracy': 0.9878571428571429, 'F-score': 0.9128205128205129}, 'SIT': {'Sensitivity': 0.9646464646464646, 'Specificity': 0.9992313604919293, 'Recall': 0.9646464646464646, 'Precision': 0.9896373056994818, 'Accuracy': 0.9967857142857143, 'F-score': 0.9769820971867007}, 'CHU': {'Sensitivity': 0.8728813559322034, 'Specificity': 0.9966442953020134, 'Recall': 0.8728813559322034, 'Precision': 0.9196428571428571, 'Accuracy': 0.9914285714285714, 'F-score': 0.8956521739130435}, 'CSI': {'Sensitivity': 0.8666666666666667, 'Specificity': 0.9853281853281853, 'Recall': 0.8666666666666667, 'Precision': 0.8272727272727273, 'Accuracy': 0.9764285714285714, 'F-score': 0.8465116279069769}, 'CSO': {'Sensitivity': 0.9597989949748744, 'Specificity': 0.9946174548250672, 'Recall': 0.9597989949748744, 'Precision': 0.9317073170731708, 'Accuracy': 0.9921428571428571, 'F-score': 0.9455445544554454}, 'FOL': {'Sensitivity': 0.685, 'Specificity': 0.9696153846153847, 'Recall': 0.685, 'Precision': 0.6342592592592593, 'Accuracy': 0.9492857142857143, 'F-score': 0.6586538461538461}, 'FKL': {'Sensitivity': 0.6226415094339622, 'Specificity': 0.9787480680061824, 'Recall': 0.6226415094339622, 'Precision': 0.7058823529411765, 'Accuracy': 0.9517857142857142, 'F-score': 0.6616541353383459}, 'BSC': {'Sensitivity': 0.8197674418604651, 'Specificity': 0.9878234398782344, 'Recall': 0.8197674418604651, 'Precision': 0.815028901734104, 'Accuracy': 0.9775, 'F-score': 0.8173913043478261}, 'SDL': {'Sensitivity': 0.7329842931937173, 'Specificity': 0.983518589497892, 'Recall': 0.7329842931937173, 'Precision': 0.7650273224043715, 'Accuracy': 0.9664285714285714, 'F-score': 0.748663101604278}}\n"
     ]
    }
   ],
   "source": [
    "stats_map = {}\n",
    "for key, value in labels.items():\n",
    "    stats_map[value] = {\n",
    "        \"Sensitivity\" : float(classification_map[value][\"TP\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"FN\"]),\n",
    "        \"Specificity\" : float(classification_map[value][\"TN\"]) / float(classification_map[value][\"TN\"] + classification_map[value][\"FP\"]),\n",
    "        \"Recall\" : float(classification_map[value][\"TP\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"FN\"]),\n",
    "        \"Precision\" : float(classification_map[value][\"TP\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"FP\"]),\n",
    "        \"Accuracy\" : float(classification_map[value][\"TP\"] + classification_map[value][\"TN\"]) / float(classification_map[value][\"TP\"] + classification_map[value][\"TN\"] + classification_map[value][\"FP\"] + classification_map[value][\"FN\"])\n",
    "    }\n",
    "    stats_map[value][\"F-score\"] = 2.0 / float(1.0 / float(stats_map[value][\"Precision\"]) + 1.0 / float(stats_map[value][\"Recall\"]))\n",
    "print(stats_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e29914317381cb5b054684ec136cf5f9d23d3fafddd70669a3da3e14954aacc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
